import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error, accuracy_score, r2_score, mean_squared_error
from sklearn.metrics import precision_score, recall_score, f1_score
import os
from datetime import datetime
import warnings
import joblib
# æ·»åŠ XGBoostå¯¼å…¥
import xgboost as xgb
import streamlit as st
warnings.filterwarnings('ignore')


# è¯·å‚è€ƒä¸Šé¢çš„ç¨‹åºæ–°å»ºä¸€ä¸ªç¨‹åº model_random_forest.py,å®ç°ä¸€ä¸ªéšæœºæ£®æ—çš„æœºå™¨å­¦ä¹ ç¨‹åºï¼Œè¦æ±‚å¦‚ä¸‹ï¼š 1ã€è¯»å–æŸä¸ªç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼Œè·å–æ•°æ®ï¼Œå‚è€ƒå·²æœ‰æ–¹æ³•ï¼› 2ã€ç”¨è¿™äº›æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œç”Ÿæˆä¸€ä¸ªæ¨¡å‹è¿›è¡Œä¿å­˜ï¼Œéœ€è¦ä¸¤ç§æ¨¡å‹ï¼› 3ã€æ¨¡å‹ç”Ÿæˆå¥½äº†ä»¥åï¼Œå¯ä»¥æŒ‡å®šè¯»å–æ–‡ä»¶ï¼Œæ¥è°ƒç”¨è¿™ä¸ªæ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œç»“æœä¿å­˜åˆ°tempç›®å½•ä¸‹ï¼› 4ã€ä¹Ÿå¯ä»¥è¯»å–æŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶ï¼Œæ¥è°ƒç”¨è¿™ä¸ªæ¨¡å‹ï¼› 5ã€è¦æ±‚æä¾›æ¨¡å‹çš„ä¼˜åŒ–å’Œæ£€æŸ¥çš„ä¾æ®ï¼Œå¯ä»¥è¿›è¡Œè°ƒå‚ï¼› 6ã€å†™å‡ºæµ‹è¯•æ–¹æ³•ï¼Œå¹¶å¯ä»¥è¿è¡Œï¼›

# å¯¼å…¥åŸæœ‰æ•°æ®è¯»å–å‡½æ•°
from model_xunlian import generate_model_data_from_files, get_prediction_files_data
from data_prepare import prepare_all_data,prepare_prediction_dir_data,prepare_prediction_data


def prepare_data_from_directory(directory_path):
    """
    ä»æŒ‡å®šç›®å½•è¯»å–æ‰€æœ‰æ•°æ®æ–‡ä»¶å¹¶å‡†å¤‡æ•°æ®é›†
    """
    # ä½¿ç”¨ç»å¯¹è·¯å¾„
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    temp_file_path = os.path.join(base_dir, "..", "data", "bak", "model_data_rf.xlsx")
    if os.path.exists(temp_file_path):
        print("æ£€æµ‹åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œç›´æ¥è¯»å–...")
        try:
            df = pd.read_excel(temp_file_path, engine='openpyxl')
            print(f'å†å²æ•°æ®é‡ï¼š{len(df)}')
            return df
        except Exception as e:
            print(f"è¯»å–ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}ï¼Œé‡æ–°ç”Ÿæˆæ•°æ®...")
    
    # è¯»å–ç›®å½•ä¸‹æ‰€æœ‰xlsxæ–‡ä»¶
    files = []
    for file in os.listdir(directory_path):
        if file.endswith('.xlsx'):
            files.append(os.path.join(directory_path, file))
    
    if not files:
        raise ValueError(f"ç›®å½• {directory_path} ä¸­æœªæ‰¾åˆ°xlsxæ–‡ä»¶")
    
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæ•°æ®æ–‡ä»¶")
    
    # è¯»å–æ–‡ä»¶ä¸­çš„æ•°æ®
    df = generate_model_data_from_files(files)
    print(f'å†å²æ•°æ®é‡ï¼š{len(df)}')

    # è¯»å–å…¶ä»–æ•°æ® æ¯æ—¥æ•´ç†çš„æ•°æ®é›†
    predictions_dir = os.path.join(base_dir, "..", "data", "predictions")
    df_other = get_prediction_files_data(predictions_dir, '0730')
    
    if df_other is not None and not df_other.empty:
        print(f'é¢„æµ‹æ•°æ®é‡ï¼š{len(df_other)}')
        # åˆå¹¶æ•°æ®
        df = pd.concat([df, df_other], ignore_index=True)
    
    print(f'æ€»æ•°æ®é‡ï¼š{len(df)}')
    # å°†dfå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œä¾›ä¸‹æ¬¡ä½¿ç”¨
    os.makedirs(os.path.dirname(temp_file_path), exist_ok=True)
    df.to_excel("../data/bak/model_data_rf.xlsx", index=False)
    return df

def optimize_model_parameters(X_train, y_train, model_type='regression', algorithm='random_forest'):
    """
    ä½¿ç”¨ç½‘æ ¼æœç´¢ä¼˜åŒ–æ¨¡å‹å‚æ•°
    """
    print("å¼€å§‹æ¨¡å‹å‚æ•°ä¼˜åŒ–...")
    
    if algorithm == 'random_forest':
        if model_type == 'regression':
            model = RandomForestRegressor(random_state=42)
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [None, 10, 20, 30],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4]
            }
        else:
            model = RandomForestClassifier(random_state=42)
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [None, 10, 20, 30],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4]
            }
    elif algorithm == 'xgboost':
        if model_type == 'regression':
            model = xgb.XGBRegressor(random_state=42)
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [3, 6, 9],
                'learning_rate': [0.01, 0.1, 0.2],
                'subsample': [0.8, 1.0]
            }
        else:
            model = xgb.XGBClassifier(random_state=42)
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [3, 6, 9],
                'learning_rate': [0.01, 0.1, 0.2],
                'subsample': [0.8, 1.0]
            }
    
    # ç½‘æ ¼æœç´¢
    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grid,
        cv=3,
        n_jobs=-1,
        verbose=1,
        scoring='accuracy' if model_type == 'classification' else 'neg_mean_absolute_error'
    )
    
    grid_search.fit(X_train, y_train)
    
    print(f"æœ€ä½³å‚æ•°: {grid_search.best_params_}")
    print(f"æœ€ä½³å¾—åˆ†: {grid_search.best_score_}")
    
    return grid_search.best_estimator_

def find_optimal_threshold(df, feature_cols, algorithm='random_forest', model_type='classification'):
    """
    å¯»æ‰¾æœ€ä¼˜çš„thresholdå€¼
    """
    print("å¼€å§‹å¯»æ‰¾æœ€ä¼˜thresholdå€¼...")
    
    # æ•°æ®é¢„å¤„ç†
    data = df.copy()
    
    # ç§»é™¤ç›®æ ‡åˆ—ä¸­çš„ç¼ºå¤±å€¼
    target_col = 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…'
    data = data.dropna(subset=[target_col])
    
    # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
    X = data[feature_cols]
    y = data[target_col]
    
    # æ¸…ç†æ•°æ®ä¸­çš„æ— æ•ˆå€¼
    # å°† '--' ç­‰æ— æ•ˆå­—ç¬¦ä¸²æ›¿æ¢ä¸º NaN
    X = X.replace(['--', 'None', 'null', ''], np.nan)
    y = y.replace(['--', 'None', 'null', ''], np.nan)
    
    # ç§»é™¤åŒ…å« NaN çš„è¡Œ
    valid_indices = X.dropna().index.intersection(y.dropna().index)

    X = X.loc[valid_indices]
    y = y.loc[valid_indices]

    print(f"æ•°æ®...{len(X)}ï¼Œâ€œåˆ—â€æ•°æ®é‡ï¼š{len(y)}")
    # å¤„ç†åˆ†ç±»ç‰¹å¾
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns
    if not categorical_cols.empty:
        le = LabelEncoder()
        for col in categorical_cols:
            X[col] = le.fit_transform(X[col].astype(str))
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42)
    
    if model_type == 'classification':
        # æµ‹è¯•ä¸åŒçš„thresholdå€¼
        thresholds = range(5, 15, 1)  # ä»0åˆ°30ï¼Œæ­¥é•¿ä¸º1
        best_threshold = 0
        best_score = -1
        best_metrics = {}
        
        print(f"æµ‹è¯•thresholdå€¼èŒƒå›´: {min(thresholds)} - {max(thresholds)}")
        
        results = []
        
        for threshold in thresholds:
            # åˆ›å»ºåˆ†ç±»ç›®æ ‡å˜é‡
            y_train_cls = (y_train > threshold).astype(int)
            y_test_cls = (y_test > threshold).astype(int)
            
            # åˆå§‹åŒ–æ¨¡å‹
            if algorithm == 'random_forest':
                model = RandomForestClassifier(n_estimators=100, random_state=42)
            elif algorithm == 'xgboost':
                model = xgb.XGBClassifier(n_estimators=100, random_state=42)
            
            # å¯¹æ¨¡å‹è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
            print(f"å¯¹threshold={threshold}è¿›è¡Œæ¨¡å‹è°ƒä¼˜...")
            optimized_model = optimize_model_parameters(X_train, y_train_cls, 'classification', algorithm)
            
            # è®­ç»ƒä¼˜åŒ–åçš„æ¨¡å‹
            optimized_model.fit(X_train, y_train_cls)
            
            # é¢„æµ‹
            y_pred = optimized_model.predict(X_test)
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            accuracy = accuracy_score(y_test_cls, y_pred)
            precision = precision_score(y_test_cls, y_pred, average='weighted', zero_division=0)
            recall = recall_score(y_test_cls, y_pred, average='weighted', zero_division=0)
            f1 = f1_score(y_test_cls, y_pred, average='weighted', zero_division=0)
            
            # ä½¿ç”¨F1åˆ†æ•°ä½œä¸ºä¸»è¦è¯„ä¼°æŒ‡æ ‡
            score = f1
            
            results.append({
                'threshold': threshold,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1
            })
            
            if score > best_score:
                best_score = score
                best_threshold = threshold
                best_metrics = {
                    'threshold': threshold,
                    'accuracy': accuracy,
                    'precision': precision,
                    'recall': recall,
                    'f1_score': f1
                }
            
            print(f"Threshold: {threshold:2d}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}")
        
        print(f"\næœ€ä¼˜thresholdå€¼: {best_threshold}")
        print(f"å¯¹åº”çš„è¯„ä¼°æŒ‡æ ‡: {best_metrics}")
        
        # å°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶
        results_df = pd.DataFrame(results)
        os.makedirs("temp", exist_ok=True)
        results_df.to_excel(f"temp/threshold_optimization_results_{algorithm}_{model_type}.xlsx", index=False)
        print(f"thresholdä¼˜åŒ–ç»“æœå·²ä¿å­˜è‡³: temp/threshold_optimization_results_{algorithm}_{model_type}.xlsx")
        
        return best_threshold, best_metrics, results_df
    
    elif model_type == 'regression':
        # å¯¹äºå›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„è¯„ä¼°æ–¹æ³•
        # æˆ‘ä»¬å°†é¢„æµ‹å€¼ä¸å®é™…å€¼çš„å·®å¼‚ä½œä¸ºè¯„ä¼°æ ‡å‡†
        
        # åˆå§‹åŒ–æ¨¡å‹
        if algorithm == 'random_forest':
            model = RandomForestRegressor(n_estimators=100, random_state=42)
        elif algorithm == 'xgboost':
            model = xgb.XGBRegressor(n_estimators=100, random_state=42)
        
        # å¯¹æ¨¡å‹è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
        print("å¯¹å›å½’æ¨¡å‹è¿›è¡Œè°ƒä¼˜...")
        optimized_model = optimize_model_parameters(X_train, y_train, 'regression', algorithm)
        
        # è®­ç»ƒä¼˜åŒ–åçš„æ¨¡å‹
        optimized_model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred = optimized_model.predict(X_test)
        
        # è®¡ç®—å›å½’è¯„ä¼°æŒ‡æ ‡
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        
        metrics = {
            'MAE': mae,
            'R2': r2,
            'RMSE': rmse
        }
        
        print(f"å›å½’æ¨¡å‹è¯„ä¼°ç»“æœ: MAE={mae:.4f}, R2={r2:.4f}, RMSE={rmse:.4f}")
        
        # åˆ›å»ºç»“æœæ•°æ®æ¡†
        results_df = pd.DataFrame([{
            'MAE': mae,
            'R2': r2,
            'RMSE': rmse
        }])
        
        # ä¿å­˜ç»“æœ
        os.makedirs("temp", exist_ok=True)
        results_df.to_excel(f"temp/threshold_optimization_results_{algorithm}_{model_type}.xlsx", index=False)
        print(f"å›å½’æ¨¡å‹è¯„ä¼°ç»“æœå·²ä¿å­˜è‡³: temp/threshold_optimization_results_{algorithm}_{model_type}.xlsx")
        
        # å›å½’æ¨¡å‹ä¸éœ€è¦thresholdï¼Œè¿”å›é»˜è®¤å€¼
        return None, metrics, results_df

def train_and_save_models(df, target_col, feature_cols, model_type='regression', threshold=7, algorithm='random_forest'):
    """
    è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹å¹¶ä¿å­˜
    """
    # æ•°æ®é¢„å¤„ç†
    data = df.copy()
    
    # ç§»é™¤ç›®æ ‡åˆ—ä¸­çš„ç¼ºå¤±å€¼
    data = data.dropna(subset=[target_col])
    
    # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
    X = data[feature_cols]
    y = data[target_col]
    
    # æ¸…ç†æ•°æ®ä¸­çš„æ— æ•ˆå€¼
    # å°† '--' ç­‰æ— æ•ˆå­—ç¬¦ä¸²æ›¿æ¢ä¸º NaN
    X = X.replace(['--', 'None', 'null', ''], np.nan)
    y = y.replace(['--', 'None', 'null', ''], np.nan)
    
    # ç§»é™¤åŒ…å« NaN çš„è¡Œ
    valid_indices = X.dropna().index.intersection(y.dropna().index)
    X = X.loc[valid_indices]
    y = y.loc[valid_indices]
    print(f"æ•°æ®...{len(X)}ï¼Œâ€œåˆ—â€æ•°æ®é‡ï¼š{len(y)}")

    # å¤„ç†åˆ†ç±»ç‰¹å¾
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns
    if not categorical_cols.empty:
        le = LabelEncoder()
        for col in categorical_cols:
            X[col] = le.fit_transform(X[col].astype(str))
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42)
    
    # åˆå§‹åŒ–æ¨¡å‹
    if algorithm == 'random_forest':
        if model_type == 'regression':
            base_model = RandomForestRegressor(n_estimators=100, random_state=42)
        else:  # classification
            # åˆ›å»ºåˆ†ç±»ç›®æ ‡å˜é‡
            if target_col == 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…':
                y_train = (y_train > threshold).astype(int)
                y_test = (y_test > threshold).astype(int)
            base_model = RandomForestClassifier(n_estimators=100, random_state=42)
    elif algorithm == 'xgboost':
        if model_type == 'regression':
            base_model = xgb.XGBRegressor(n_estimators=100, random_state=42)
        else:  # classification
            # åˆ›å»ºåˆ†ç±»ç›®æ ‡å˜é‡
            if target_col == 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…':
                y_train = (y_train > threshold).astype(int)
                y_test = (y_test > threshold).astype(int)
            base_model = xgb.XGBClassifier(n_estimators=100, random_state=42)
    
    # è®­ç»ƒåŸºç¡€æ¨¡å‹
    base_model.fit(X_train, y_train)
    
    # ä¼˜åŒ–å‚æ•°çš„æ¨¡å‹
    optimized_model = optimize_model_parameters(X_train, y_train, model_type, algorithm)
    optimized_model.fit(X_train, y_train)
    
    # é¢„æµ‹
    basic_pred = base_model.predict(X_test)
    optimized_pred = optimized_model.predict(X_test)
    
    # è¯„ä¼°æ¨¡å‹
    if model_type == 'regression':
        basic_metrics = {
            'MAE': mean_absolute_error(y_test, basic_pred),
            'R2': r2_score(y_test, basic_pred),
            'RMSE': np.sqrt(mean_squared_error(y_test, basic_pred))
        }
        
        optimized_metrics = {
            'MAE': mean_absolute_error(y_test, optimized_pred),
            'R2': r2_score(y_test, optimized_pred),
            'RMSE': np.sqrt(mean_squared_error(y_test, optimized_pred))
        }
    else:
        basic_metrics = {
            'Accuracy': accuracy_score(y_test, basic_pred),
            'Precision': precision_score(y_test, basic_pred, average='weighted', zero_division=0),
            'Recall': recall_score(y_test, basic_pred, average='weighted', zero_division=0),
            'F1_Score': f1_score(y_test, basic_pred, average='weighted', zero_division=0)
        }
        
        optimized_metrics = {
            'Accuracy': accuracy_score(y_test, optimized_pred),
            'Precision': precision_score(y_test, optimized_pred, average='weighted', zero_division=0),
            'Recall': recall_score(y_test, optimized_pred, average='weighted', zero_division=0),
            'F1_Score': f1_score(y_test, optimized_pred, average='weighted', zero_division=0)
        }
    
    print(f"åŸºç¡€æ¨¡å‹è¯„ä¼°ç»“æœ: {basic_metrics}")
    print(f"ä¼˜åŒ–æ¨¡å‹è¯„ä¼°ç»“æœ: {optimized_metrics}")
    
    # åˆ›å»ºæ¨¡å‹ç›®å½•
    os.makedirs("../models", exist_ok=True)
    y = (y > threshold).astype(int)
    base_model.fit(X, y)
    optimized_model.fit(X, y)

    # ä¿å­˜åŸºç¡€æ¨¡å‹
    model_data_basic = {
        'model': base_model,
        'feature_cols': feature_cols,
        'label_encoder': le if not categorical_cols.empty else None,
        'categorical_cols': categorical_cols,
        'model_type': model_type,
        'threshold': threshold if model_type == 'classification' else None,
        'metrics': basic_metrics,
        'algorithm': algorithm
    }
    joblib.dump(model_data_basic, f"../models/{algorithm}_{model_type}_basic_model.pkl")
    print(f"åŸºç¡€{model_type}æ¨¡å‹å·²ä¿å­˜")
    
    # ä¿å­˜ä¼˜åŒ–æ¨¡å‹
    model_data_optimized = {
        'model': optimized_model,
        'feature_cols': feature_cols,
        'label_encoder': le if not categorical_cols.empty else None,
        'categorical_cols': categorical_cols,
        'model_type': model_type,
        'threshold': threshold if model_type == 'classification' else None,
        'metrics': optimized_metrics,
        'algorithm': algorithm
    }
    joblib.dump(model_data_optimized, f"../models/{algorithm}_{model_type}_optimized_model.pkl")
    print(f"ä¼˜åŒ–{model_type}æ¨¡å‹å·²ä¿å­˜")
    
    return model_data_basic, model_data_optimized

def predict_with_saved_models(file_path, output_path=None, algorithms=['random_forest'], model='basic'):
    """
    ä½¿ç”¨ä¿å­˜çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ model_type='basic' or 'optimized'
    """
    # åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")
    # è¯»å–è¾“å…¥æ–‡ä»¶
    df = pd.read_excel(file_path, engine='openpyxl')
    
    # åˆ›å»ºtempç›®å½•ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„
    base_dir = os.path.dirname(os.path.abspath(__file__))
    temp_dir = os.path.join(base_dir, "temp")
    os.makedirs(temp_dir, exist_ok=True)
    
    # å­˜å‚¨æ‰€æœ‰é¢„æµ‹ç»“æœ
    results = df.copy()
    
    # éå†æ‰€æœ‰ç®—æ³•
    for algorithm in algorithms:
        # åŠ è½½æ¨¡å‹
        model_dir = os.path.join(base_dir, "..", "models")
        if algorithm == 'random_forest':
            regression_model = joblib.load(os.path.join(model_dir, f"{algorithm}_regression_{model}_model.pkl"))
            classification_model = joblib.load(os.path.join(model_dir, f"{algorithm}_classification_{model}_model.pkl"))
        elif algorithm == 'xgboost':
            regression_model = joblib.load(os.path.join(model_dir, f"xgboost_regression_{model}_model.pkl"))
            classification_model = joblib.load(os.path.join(model_dir, f"xgboost_classification_{model}_model.pkl"))
        
        # å‡†å¤‡å›å½’æ¨¡å‹ç‰¹å¾æ•°æ®
        X_reg = df[regression_model['feature_cols']].copy()
        if regression_model['label_encoder'] is not None and not regression_model['categorical_cols'].empty:
            for col in regression_model['categorical_cols']:
                if col in X_reg.columns:
                    X_reg[col] = regression_model['label_encoder'].fit_transform(X_reg[col].astype(str))
        
        # å‡†å¤‡åˆ†ç±»æ¨¡å‹ç‰¹å¾æ•°æ®
        X_cls = df[classification_model['feature_cols']].copy()
        if classification_model['label_encoder'] is not None and not classification_model['categorical_cols'].empty:
            for col in classification_model['categorical_cols']:
                if col in X_cls.columns:
                    X_cls[col] = classification_model['label_encoder'].fit_transform(X_cls[col].astype(str))
        
        # è¿›è¡Œé¢„æµ‹
        reg_predictions = regression_model['model'].predict(X_reg)
        cls_predictions = classification_model['model'].predict(X_cls)
        
        # æ·»åŠ é¢„æµ‹ç»“æœåˆ°æ•°æ®æ¡†ï¼Œä½¿ç”¨ç®—æ³•åç§°ä½œä¸ºå‰ç¼€
        results[f'{algorithm}_Reg'] = reg_predictions
        results[f'{algorithm}_Cf'] = cls_predictions

        # æ‰“å°å‡ºé¢„æµ‹ç»“æœä¸º1çš„è¡Œ
        print(f"é¢„æµ‹ç»“æœä¸º1çš„è¡Œï¼š{model} {algorithm}")
        print(results[results[f'{algorithm}_Cf'] == 1])
        
        # æ‰“å°å‡ºé¢„æµ‹ç»“æœå¤§äº14çš„è¡Œ
        print(f"é¢„æµ‹ç»“æœå¤§äº14çš„è¡Œï¼š{model} {algorithm}")
        print(results[results[f'{algorithm}_Reg'] > 14])
    
    # ä¿å­˜ç»“æœ
    if output_path is None:
        # æ–‡ä»¶åæ”¹ä¸ºè¾“å…¥æ–‡ä»¶ååŠ ä¸Š_with_results.xlsxï¼ŒåŠ ä¸Šç›®å½• temp,åªå–æ–‡ä»¶åï¼Œå¢åŠ ä¼ å…¥æ¨¡å‹çš„å‚æ•°
        file_name = os.path.basename(file_path)
        # æ–‡ä»¶åæ”¹ä¸ºè¾“å…¥æ–‡ä»¶ååŠ ä¸Š_with_results.xlsx
        # ä¿®æ”¹æ–‡ä»¶åä»¥åŒ…å«æ‰€æœ‰ç®—æ³•åç§°
        algorithms_str = '_'.join(algorithms)
        output_path = os.path.join(temp_dir, f'{file_name}_{algorithms_str}_{model}.xlsx')

    results.to_excel(output_path, index=False)
    print(f"é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {output_path}")
    
    return results, output_path

def predict_from_directory(directory_path, algorithms=['random_forest']):
    """
    è¯»å–æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¹¶è¿›è¡Œé¢„æµ‹
    """
    # åˆ›å»ºç»“æœç›®å½•ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„
    base_dir = os.path.dirname(os.path.abspath(__file__))
    results_dir = os.path.join(base_dir, "temp", "directory_predictions")
    os.makedirs(results_dir, exist_ok=True)
    
    # è¯»å–ç›®å½•ä¸‹æ‰€æœ‰xlsxæ–‡ä»¶
    files = []
    for file in os.listdir(directory_path):
        if file.endswith('.xlsx'):
            files.append(os.path.join(directory_path, file))
    
    if not files:
        raise ValueError(f"ç›®å½• {directory_path} ä¸­æœªæ‰¾åˆ°xlsxæ–‡ä»¶")
    
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæ•°æ®æ–‡ä»¶è¿›è¡Œé¢„æµ‹")
    
    results = []
    for file_path in files:
        try:
            print(f"å¤„ç†æ–‡ä»¶: {file_path}")
            result = predict_with_saved_models(file_path, 
                                             os.path.join(results_dir, os.path.basename(file_path)),
                                             algorithms)
            results.append(result)
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    
    print(f"å·²å®Œæˆ {len(results)} ä¸ªæ–‡ä»¶çš„é¢„æµ‹")
    return results

def model_evaluation_report(model_data, X_test, y_test, model_name):
    """
    ç”Ÿæˆæ¨¡å‹è¯„ä¼°æŠ¥å‘Š
    """
    model = model_data['model']
    predictions = model.predict(X_test)
    
    # åˆ›å»ºè¯„ä¼°æŠ¥å‘Š
    report = {
        'Model_Name': model_name,
        'Number_of_Features': len(model_data['feature_cols']),
        'Number_of_Samples': len(y_test)
    }
    
    if model_data['model_type'] == 'regression':
        report.update({
            'MAE': mean_absolute_error(y_test, predictions),
            'R2': r2_score(y_test, predictions),
            'RMSE': np.sqrt(mean_squared_error(y_test, predictions))
        })
    else:
        report.update({
            'Accuracy': accuracy_score(y_test, predictions),
            'Precision': precision_score(y_test, predictions, average='weighted', zero_division=0),
            'Recall': recall_score(y_test, predictions, average='weighted', zero_division=0),
            'F1_Score': f1_score(y_test, predictions, average='weighted', zero_division=0)
        })
    
    return report

# def test_model_functionality():
#     """
#     æµ‹è¯•æ¨¡å‹åŠŸèƒ½
#     """
#     print("=== å¼€å§‹æµ‹è¯•æ¨¡å‹åŠŸèƒ½ ===")
#
#     # 1. å‡†å¤‡æ•°æ®
#     print("1. å‡†å¤‡æ•°æ®...")
#     # ç¡®ä¿æµ‹è¯•ç›®å½•å­˜åœ¨
#     test_data_dir = "../alert/"
#     os.makedirs(test_data_dir, exist_ok=True)
#
#     # æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦æœ‰æ•°æ®æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºç¤ºä¾‹æ•°æ®
#     data_files = [f for f in os.listdir(test_data_dir) if f.endswith('.xlsx')]
#     if not data_files:
#         print("æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®...")
#         # åˆ›å»ºç¤ºä¾‹æ•°æ®
#         sample_data = pd.DataFrame({
#             'å½“æ—¥æ¶¨å¹…': np.random.randn(200),
#             'é‡æ¯”': np.random.randn(200),
#             'æ€»é‡‘é¢': np.random.randn(200),
#             'ä¿¡å·å¤©æ•°': np.random.randint(1, 10, 200),
#             'Q': np.random.randn(200),
#             'band_width': np.random.randn(200),
#             'min_value': np.random.randn(200),
#             'max_value': np.random.randn(200),
#             'å‡€é¢': np.random.randn(200),
#             'å‡€æµå…¥': np.random.randn(200),
#             'å½“æ—¥èµ„é‡‘æµå…¥': np.random.randn(200),
#             'æ¬¡æ—¥æ¶¨å¹…': np.random.randn(200),
#             'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…': np.random.randint(0, 2, 200) * 30
#         })
#         sample_data.to_excel(os.path.join(test_data_dir, "sample_data.xlsx"), index=False)
#
#     df = prepare_data_from_directory("../alert/")
#
#     # 2. å®šä¹‰ç‰¹å¾å’Œç›®æ ‡
#     feature_combinations = {
#         'Basic_Features': ['å½“æ—¥æ¶¨å¹…', 'ä¿¡å·å¤©æ•°', 'å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥'],
#         'All_Features': ['å½“æ—¥æ¶¨å¹…', 'é‡æ¯”','æ€»é‡‘é¢', 'ä¿¡å·å¤©æ•°','Q','band_width','min_value','max_value','å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥']
#     }
#
#     target_col_reg = 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…'
#     target_col_cls = 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…'
#
#     # 3. è®­ç»ƒå›å½’æ¨¡å‹
#     print("2. è®­ç»ƒå›å½’æ¨¡å‹...")
#     reg_basic, reg_opt = train_and_save_models(
#         df, target_col_reg, feature_combinations['All_Features'], 'regression'
#     )
#
#     # 4. è®­ç»ƒåˆ†ç±»æ¨¡å‹
#     print("3. è®­ç»ƒåˆ†ç±»æ¨¡å‹...")
#     cls_basic, cls_opt = train_and_save_models(
#         df, target_col_cls, feature_combinations['Basic_Features'], 'classification', threshold=14
#     )
#
#     # 5. æµ‹è¯•å•æ–‡ä»¶é¢„æµ‹
#     print("4. æµ‹è¯•å•æ–‡ä»¶é¢„æµ‹...")
#     # åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶
#     test_df = df.head(100)  # å–å‰100è¡Œä½œä¸ºæµ‹è¯•æ•°æ®
#     test_file = "temp/test_data.xlsx"
#     test_df.to_excel(test_file, index=False)
#
#     result = predict_with_saved_models(test_file)
#     print(f"å•æ–‡ä»¶é¢„æµ‹å®Œæˆï¼Œç»“æœè¡Œæ•°: {len(result)}")
#
#     # 6. æµ‹è¯•ç›®å½•é¢„æµ‹
#     print("5. æµ‹è¯•ç›®å½•é¢„æµ‹...")
#     os.makedirs("temp/test_directory", exist_ok=True)
#     test_df.head(50).to_excel("temp/test_directory/test1.xlsx", index=False)
#     test_df.tail(50).to_excel("temp/test_directory/test2.xlsx", index=False)
#
#     dir_results = predict_from_directory("temp/test_directory")
#     print(f"ç›®å½•é¢„æµ‹å®Œæˆï¼Œå¤„ç†æ–‡ä»¶æ•°: {len(dir_results)}")
#
#     print("=== æ¨¡å‹åŠŸèƒ½æµ‹è¯•å®Œæˆ ===")

def main():
    """
    ä¸»å‡½æ•°
    """
    # è¿è¡Œæµ‹è¯•

    # å¦‚æœéœ€è¦å®é™…ä½¿ç”¨ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
    df = prepare_all_data("0827")

    # è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹ - éšæœºæ£®æ—
    # feature_cols = ['å½“æ—¥æ¶¨å¹…', 'ä¿¡å·å¤©æ•°', 'å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥']
    feature_cols =  ['å½“æ—¥æ¶¨å¹…', 'é‡æ¯”','æ€»é‡‘é¢','ä¿¡å·å¤©æ•°','Q','band_width','å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥']


    # å®šä¹‰å¤šç§ç‰¹å¾åˆ—ç»„åˆè¿›è¡Œæµ‹è¯•
    feature_combinations = {
        'Basic_Features': ['å½“æ—¥æ¶¨å¹…', 'ä¿¡å·å¤©æ•°', 'å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥'],
        'Price_and_Flow_Features': ['å½“æ—¥æ¶¨å¹…', 'æ€»é‡‘é¢', 'å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥'],
        'Timing_Features':  ['å½“æ—¥æ¶¨å¹…', 'é‡æ¯”', 'æ€»é‡‘é¢','ä¿¡å·å¤©æ•°', 'å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥'],
        'Flow_Features': ['å½“æ—¥æ¶¨å¹…', 'é‡æ¯”','æ€»é‡‘é¢','ä¿¡å·å¤©æ•°','Q','å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥'],
        'last_Features': ['å½“æ—¥æ¶¨å¹…', 'é‡æ¯”','æ€»é‡‘é¢','ä¿¡å·å¤©æ•°','Q','band_width','å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥'],
        'All_Features': ['å½“æ—¥æ¶¨å¹…', 'é‡æ¯”','æ€»é‡‘é¢','ä¿¡å·å¤©æ•°','Q','band_width','min_value','max_value','å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥']
    }

    # æ¨¡å‹è°ƒä¼˜å’Œå‚æ•°è°ƒä¼˜
    # find_optimal_threshold(df, feature_cols, algorithm='random_forest', model_type='classification')
    # find_optimal_threshold(df, feature_cols, algorithm='xgboost', model_type='classification')

    # find_optimal_threshold(df, feature_cols, algorithm='xgboost', model_type='regression')
    # find_optimal_threshold(df, feature_cols, algorithm='random_forest', model_type='regression')



    train_and_save_models(df, 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…', feature_cols, 'regression', algorithm='random_forest')
    train_and_save_models(df, 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…', feature_cols, 'classification', algorithm='random_forest')
    #
    # # è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹ - XGBoost
    train_and_save_models(df, 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…', feature_cols, 'regression', algorithm='xgboost')
    train_and_save_models(df, 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…', feature_cols, 'classification', algorithm='xgboost')
    #
    # # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
    # predict_with_saved_models("../data/predictions/1000/08250950_0952.xlsx", algorithms=['random_forest','xgboost'])

def streamlit_app():
    """
    Streamlitåº”ç”¨ç•Œé¢
    """
    st.set_page_config(page_title="è‚¡ç¥¨é¢„æµ‹æ¨¡å‹", layout="wide")
    st.title("ğŸ“ˆ è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ç³»ç»Ÿ")
    
    # ä¾§è¾¹æ 
    st.sidebar.header("æ¨¡å‹æ“ä½œ")
    operation = st.sidebar.radio("é€‰æ‹©æ“ä½œ", ["æ¨¡å‹è®­ç»ƒ", "æ¨¡å‹é¢„æµ‹", "æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯"])
    
    if operation == "æ¨¡å‹è®­ç»ƒ":
        st.header("æ¨¡å‹è®­ç»ƒ")
        
        # æ•°æ®å‡†å¤‡
        if st.button("å‡†å¤‡è®­ç»ƒæ•°æ®"):
            with st.spinner("æ­£åœ¨å‡†å¤‡æ•°æ®..."):
                try:
                    df = prepare_all_data("0827")
                    st.success(f"æ•°æ®å‡†å¤‡å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
                    st.session_state['train_data'] = df
                except Exception as e:
                    st.error(f"æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        
        # ç‰¹å¾é€‰æ‹©
        feature_cols = ['å½“æ—¥æ¶¨å¹…', 'é‡æ¯”','æ€»é‡‘é¢','ä¿¡å·å¤©æ•°','Q','band_width','å‡€é¢', 'å‡€æµå…¥', 'å½“æ—¥èµ„é‡‘æµå…¥']
        
        # æ¨¡å‹è®­ç»ƒ
        if st.button("è®­ç»ƒæ¨¡å‹") and 'train_data' in st.session_state:
            with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
                try:
                    df = st.session_state['train_data']
                    
                    # è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
                    rf_reg_basic, rf_reg_opt = train_and_save_models(
                        df, 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…', feature_cols, 'regression', algorithm='random_forest')
                    rf_cls_basic, rf_cls_opt = train_and_save_models(
                        df, 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…', feature_cols, 'classification', algorithm='random_forest')
                    
                    # è®­ç»ƒXGBoostæ¨¡å‹
                    xgb_reg_basic, xgb_reg_opt = train_and_save_models(
                        df, 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…', feature_cols, 'regression', algorithm='xgboost')
                    xgb_cls_basic, xgb_cls_opt = train_and_save_models(
                        df, 'æ¬¡æ—¥æœ€é«˜æ¶¨å¹…', feature_cols, 'classification', algorithm='xgboost')
                    
                    st.success("æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆå¹¶å·²ä¿å­˜ï¼")
                    
                    # æ˜¾ç¤ºæ¨¡å‹è¯„ä¼°ç»“æœ
                    st.subheader("æ¨¡å‹è¯„ä¼°ç»“æœ")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("éšæœºæ£®æ—å›å½’æ¨¡å‹ (åŸºç¡€):", rf_reg_basic['metrics'])
                        st.write("éšæœºæ£®æ—åˆ†ç±»æ¨¡å‹ (åŸºç¡€):", rf_cls_basic['metrics'])
                        st.write("éšæœºæ£®æ—å›å½’æ¨¡å‹ (ä¼˜åŒ–):", rf_reg_opt['metrics'])
                        st.write("éšæœºæ£®æ—åˆ†ç±»æ¨¡å‹ (ä¼˜åŒ–):", rf_cls_opt['metrics'])
                    
                    with col2:
                        st.write("XGBoostå›å½’æ¨¡å‹ (åŸºç¡€):", xgb_reg_basic['metrics'])
                        st.write("XGBooståˆ†ç±»æ¨¡å‹ (åŸºç¡€):", xgb_cls_basic['metrics'])
                        st.write("XGBoostå›å½’æ¨¡å‹ (ä¼˜åŒ–):", xgb_reg_opt['metrics'])
                        st.write("XGBooståˆ†ç±»æ¨¡å‹ (ä¼˜åŒ–):", xgb_cls_opt['metrics'])
                        
                except Exception as e:
                    st.error(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
    
    elif operation == "æ¨¡å‹é¢„æµ‹":
        st.header("æ¨¡å‹é¢„æµ‹")
        
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader("ä¸Šä¼ é¢„æµ‹æ•°æ®æ–‡ä»¶ (Excel)", type=['xlsx'])
        
        if uploaded_file is not None:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            with open(f"temp/uploaded_file.xlsx", "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            
            # é€‰æ‹©æ¨¡å‹ç±»å‹
            algorithms = st.multiselect("é€‰æ‹©æ¨¡å‹ç®—æ³•", ['random_forest', 'xgboost'], default=['random_forest'])
            model_type = st.selectbox("é€‰æ‹©æ¨¡å‹ç‰ˆæœ¬", ['basic', 'optimized'])
            
            # æ‰§è¡Œé¢„æµ‹
            if st.button("å¼€å§‹é¢„æµ‹"):
                with st.spinner("æ­£åœ¨æ‰§è¡Œé¢„æµ‹..."):
                    try:
                        result, output_path = predict_with_saved_models(
                            "temp/uploaded_file.xlsx",
                            algorithms=algorithms,
                            model=model_type
                        )
                        
                        st.success("é¢„æµ‹å®Œæˆï¼")
                        
                        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                        st.subheader("é¢„æµ‹ç»“æœ")
                        st.dataframe(result)
                        
                        # æä¾›ä¸‹è½½
                        output_file = f"temp/prediction_result.xlsx"
                        result.to_excel(output_file, index=False)
                        
                        with open(output_file, "rb") as file:
                            st.download_button(
                                label="ä¸‹è½½é¢„æµ‹ç»“æœ",
                                data=file,
                                file_name="prediction_result.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                            
                        # æ˜¾ç¤ºé¢„æµ‹ç»Ÿè®¡
                        st.subheader("é¢„æµ‹ç»Ÿè®¡")
                        for algorithm in algorithms:
                            reg_col = f'{algorithm}_Reg'
                            cls_col = f'{algorithm}_Cf'
                            
                            if reg_col in result.columns:
                                st.write(f"{algorithm} å›å½’é¢„æµ‹ - å¹³å‡å€¼: {result[reg_col].mean():.2f}")
                            
                            if cls_col in result.columns:
                                positive_count = (result[cls_col] == 1).sum()
                                st.write(f"{algorithm} åˆ†ç±»é¢„æµ‹ - æ­£å‘é¢„æµ‹æ•°é‡: {positive_count}")
                                
                    except Exception as e:
                        st.error(f"é¢„æµ‹å¤±è´¥: {e}")
    
    elif operation == "æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯":
        st.header("æ¨¡å‹ä¿¡æ¯")
        
        # æ˜¾ç¤ºå·²ä¿å­˜çš„æ¨¡å‹
        model_dir = "../models"
        if os.path.exists(model_dir):
            models = os.listdir(model_dir)
            if models:
                st.write("å·²ä¿å­˜çš„æ¨¡å‹:")
                for model in models:
                    st.write(f"- {model}")
            else:
                st.info("æš‚æ— å·²ä¿å­˜çš„æ¨¡å‹")
        else:
            st.info("æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")

if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦åœ¨Streamlitç¯å¢ƒä¸­è¿è¡Œ
    # ä¿®å¤: ä½¿ç”¨æ›´å…¼å®¹çš„æ–¹æ³•æ£€æµ‹Streamlitç¯å¢ƒ
    try:
        # æ–°çš„æ£€æµ‹æ–¹æ³•ï¼šæ£€æŸ¥æ˜¯å¦åœ¨Streamlitä¸­è¿è¡Œ
        is_streamlit_run = (
            "STREAMLIT_RUN" in os.environ or 
            any("streamlit" in arg for arg in os.sys.argv) or
            os.environ.get("IS_STREAMLIT", False) or
            # æ·»åŠ å¯¹_streamlit_runå±æ€§çš„æ£€æŸ¥ï¼Œè¿™æ˜¯Streamlit 1.0+çš„æ ‡è¯†
            (hasattr(st, '_is_running_with_streamlit') and st._is_running_with_streamlit)
        )
    except:
        is_streamlit_run = False
    
    if is_streamlit_run:
        streamlit_app()
    else:
        # åŸå§‹å‘½ä»¤è¡Œæ¨¡å¼
        # model='basic' or 'optimized'
        # main()
        # predict_with_saved_models("../data/predictions/1000/08250950_0952.xlsx", algorithms=['random_forest','xgboost'],model='optimized')
        # predict_with_saved_models("../data/predictions/1200/08251134_1135.xlsx", algorithms=['random_forest','xgboost'],model='optimized')
        # predict_with_saved_models("../data/predictions/1400/08251421_1422.xlsx", algorithms=['random_forest','xgboost'],model='optimized')
        # predict_with_saved_models("../data/predictions/1600/08251518_1520.xlsx", algorithms=['random_forest','xgboost'],model='optimized')

        # predict_with_saved_models("../data/predictions/1000/08260955_0957.xlsx", algorithms=['random_forest','xgboost'],model='optimized')

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ç»™å‡ºæç¤º
        base_dir = os.path.dirname(os.path.abspath(__file__))
        predict_file = os.path.join(base_dir, "..", "data", "predictions", "1600", "08291641_1643.xlsx")
        if os.path.exists(predict_file):
            predict_with_saved_models(predict_file, algorithms=['random_forest','xgboost'],model='optimized')
        else:
            print(f"è­¦å‘Š: é¢„æµ‹æ–‡ä»¶ {predict_file} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–å…ˆç”Ÿæˆé¢„æµ‹æ•°æ®")
            # åˆ—å‡ºç›®å½•ä¸­å¯ç”¨çš„æ–‡ä»¶ä¾›å‚è€ƒ
            predict_dir = os.path.join(base_dir, "..", "data", "predictions", "1600")
            if os.path.exists(predict_dir):
                available_files = [f for f in os.listdir(predict_dir) if f.endswith('.xlsx')]
                if available_files:
                    print(f"åœ¨ {predict_dir} ç›®å½•ä¸­æ‰¾åˆ°ä»¥ä¸‹å¯ç”¨æ–‡ä»¶:")
                    for f in available_files:
                        print(f"  - {f}")
                else:
                    print(f"åœ¨ {predict_dir} ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½•Excelæ–‡ä»¶")
            else:
                print(f"ç›®å½• {predict_dir} ä¸å­˜åœ¨")