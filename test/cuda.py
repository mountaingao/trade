import torch

def verify_dl_environment():
    """æ·±åº¦å­¦ä¹ ç¯å¢ƒå®Œæ•´æ€§éªŒè¯å‡½æ•°"""

    # æ ¸å¿ƒç»„ä»¶ç‰ˆæœ¬éªŒè¯
    print("âœ… PyTorchç‰ˆæœ¬éªŒè¯:", torch.__version__)
    print("âœ… CUDAå·¥å…·åŒ…ç‰ˆæœ¬:", torch.version.cuda)
    print("âœ… cuDNNåŠ é€Ÿåº“ç‰ˆæœ¬:", torch.backends.cudnn.version())

    # GPUç¡¬ä»¶ä¿¡æ¯æ£€æµ‹
    if torch.cuda.is_available():
        print("\nğŸ”¥ GPUåŠ é€ŸçŠ¶æ€ï¼šå·²æ¿€æ´»")
        print(f"â€¢ å½“å‰æ˜¾å¡å‹å·: {torch.cuda.get_device_name(0)}")
        print(f"â€¢ å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}ä¸ª")
        print(f"â€¢ æ˜¾å­˜å®¹é‡: {round(torch.cuda.get_device_properties(0).total_memory/1e9, 2)}GB")
    else:
        print("\nâŒ GPUåŠ é€ŸçŠ¶æ€ï¼šæœªæ£€æµ‹åˆ°å¯ç”¨æ˜¾å¡")

if __name__ == "__main__":
    verify_dl_environment()
